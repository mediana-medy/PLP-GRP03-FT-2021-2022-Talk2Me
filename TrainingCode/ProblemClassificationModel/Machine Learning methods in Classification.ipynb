{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AZ4Ca_G85qg"
      },
      "source": [
        "## Machine Learning ways to do classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFHYtfQ4JXZl",
        "outputId": "6da6d0a0-64fa-4d0b-f35f-ae85baa3bfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabubary size: 2450\n",
            "max length text: 196\n",
            "0.9575510204081633\n"
          ]
        }
      ],
      "source": [
        "#Data Preprocessing \n",
        "y = data['problem_type']\n",
        "X = data['situation']\n",
        "length = data['situation'].apply(len)\n",
        "data = data.assign(Len_Situation=length)\n",
        "\n",
        "# Split train & test\n",
        "text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "#tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "X_train = tokenizer.texts_to_sequences(text_train)\n",
        "X_test = tokenizer.texts_to_sequences(text_test)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "maxlen = max(len(x) for x in X_train) # longest text in train set\n",
        "print('vocabubary size:',vocab_size)\n",
        "print('max length text:',maxlen)\n",
        "\n",
        "#Padding the sentences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "#embedding dimension should align with the GLOVE\n",
        "embedding_dim = 100\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "GLOVE_6B_100D_PATH =\"/content/drive/MyDrive/PLP_SharedFolder/User_Condition_Classification_model/glove.6B.100d.txt\"\n",
        "encoding=\"utf-8\"\n",
        "with open(GLOVE_6B_100D_PATH, \"rb\") as lines:\n",
        "    embeddings_index = {line.split()[0].decode(encoding): np.array(line.split()[1:],dtype=np.float32)\n",
        "               for line in lines}\n",
        "\n",
        "# Prepare embedding matrix from pre-trained model\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Check % words with embeddings \n",
        "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
        "print(nonzero_elements / vocab_size)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5T7BkKlERUn",
        "outputId": "b4e3ca5e-b7d9-4091-a23c-e5dc1c9b8dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn import metrics \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "#Data Preprocessing \n",
        "y = data['problem_type']\n",
        "X = data['situation']\n",
        "length = data['situation'].apply(len)\n",
        "data = data.assign(Len_Situation=length)\n",
        "\n",
        "#Split train & test\n",
        "text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYm_5OII1OZ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_clf_NB = Pipeline([('vect', CountVectorizer()),   #Vectorizer\n",
        "                     ('tfidf', TfidfTransformer()), #DTM with TFIDF\n",
        "                      ('clf', RidgeClassifier()),     #ML Model\n",
        "                    ])\n",
        "text_clf_NB.fit(text_train,y_train ) \n",
        "\n",
        "##Evaluate the model\n",
        "print(\"Performance on Test Data\")\n",
        "predicted_0 = text_clf_NB.predict(text_test)\n",
        "print(\"Ridge:\",np.mean(predicted_0 == y_test) )\n",
        "\n",
        "print(\"Overall Performance\")\n",
        "predicted_1 = text_clf_NB.predict(X)\n",
        "print(\"Ridgeclassifier:\",np.mean(predicted_1 == y) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-5tJKlz0uRd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_clf_NB = Pipeline([('vect', CountVectorizer()),   #Vectorizer\n",
        "                     ('tfidf', TfidfTransformer()), #DTM with TFIDF\n",
        "                      ('clf', RandonForestClassifier(n_estimators=2000)),     #ML Model\n",
        "                    ])\n",
        "text_clf_NB.fit(text_train,y_train ) \n",
        "\n",
        "##Evaluate the model\n",
        "print(\"Performance on Test Data\")\n",
        "predicted_0 = text_clf_NB.predict(text_test)\n",
        "print(\"RF:\",np.mean(predicted_0 == y_test) )\n",
        "\n",
        "print(\"Overall Performance\")\n",
        "predicted_1 = text_clf_NB.predict(X)\n",
        "print(\"RF:\",np.mean(predicted_1 == y) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DokakSrEXyt",
        "outputId": "885b3e74-65be-427a-87df-f54ae0d3aa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance on Test Data\n",
            "VC: 0.7666666666666667\n",
            "Overall Performance\n",
            "votingclassifier: 0.9276923076923077\n"
          ]
        }
      ],
      "source": [
        "#####################Build training pipeline using  Naïve Bayes Model\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=2000, random_state=1)\n",
        "clf3 = RidgeClassifier()\n",
        "clf4=svm.LinearSVC(C=1.0)\n",
        "text_clf_NB = Pipeline([('vect', CountVectorizer()),   #Vectorizer\n",
        "                     ('tfidf', TfidfTransformer()), #DTM with TFIDF\n",
        "                      ('clf3', VotingClassifier(estimators=[\n",
        "               ('rf', clf2), ('gnb', clf3),('svm',clf4)],voting='hard')),     #ML Model\n",
        "                    ])\n",
        "\n",
        "\n",
        "text_clf_NB.fit(text_train,y_train ) \n",
        "\n",
        "##Evaluate the model\n",
        "print(\"Performance on Test Data\")\n",
        "predicted_0 = text_clf_NB.predict(text_test)\n",
        "print(\"VC:\",np.mean(predicted_0 == y_test) )\n",
        "\n",
        "print(\"Overall Performance\")\n",
        "predicted_1 = text_clf_NB.predict(X)\n",
        "print(\"votingclassifier:\",np.mean(predicted_1 == y) )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Lojy4xv4OGVT",
        "BP0NvmPHvBNN",
        "-q6_IqmGvEBE",
        "5Vn1YybaOEad",
        "3tgkJGgiJ7NV",
        "PQ7pR--uKMZK",
        "IyqqiqmFIkFg"
      ],
      "name": "Copy of esconv_counselchat_Classifier.ipynb（副本）",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
